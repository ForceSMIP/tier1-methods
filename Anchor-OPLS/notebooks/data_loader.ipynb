{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590e5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22308146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting low DIV for train and high DIV for test\n",
    "models = ['MIROC6', 'CESM2', 'CanESM5', 'MIROC-ES2L', 'MPI-ESM1-2-LR']\n",
    "ref_period = ('1850-01-01', '2000-01-01')\n",
    "coarsen_factor = 12\n",
    "time_scale = 'month' # Only yearly or montly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0056ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(models, var='pr', time_scale='month', ref_period=None, path='../../AnchorMultivariateAnalysis/data/ForceSMIP/Training/Amon/tas/ForceSMIP/', coarsen_factor=None, cp_anomalies=True) :\n",
    "    ensemble = {}\n",
    "    flag = True\n",
    "    for model in models:\n",
    "        print('## Model {}'.format(model))\n",
    "        # Loop through each file\n",
    "        directory = path + model\n",
    "        # Define the file path\n",
    "        listdir = os.listdir(directory)\n",
    "\n",
    "        data = None\n",
    "        ensemble[model] = {}\n",
    "        for i, file in enumerate(listdir, start=1):\n",
    "            if i > 3:\n",
    "                break\n",
    "            print('File {}/{}'.format(i,len(listdir)), end='\\r')\n",
    "            # Reading temperature file\n",
    "            ## Open the NetCDF file using xarray\n",
    "            file_path = os.path.join(directory, file)\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            # Compute anomalies\n",
    "            if time_scale == 'month':\n",
    "                if cp_anomalies:\n",
    "                    climatology = ds.groupby('time.month').mean(dim='time')\n",
    "                    anomalies = ds.groupby('time.month') - climatology\n",
    "                else :\n",
    "                    anomalies = ds\n",
    "                \n",
    "            elif time_scale == 'year' :\n",
    "                # Extracting yearly avergaes\n",
    "                ds_yearly = ds.resample(time='1Y').mean()\n",
    "                # Calculate the mean over the reference period for each grid point\n",
    "                mean_ref_period = ds_yearly.sel(time=slice(ref_period[0], ref_period[1])).mean(dim='time')\n",
    "                anomalies = ds_yearly - mean_ref_period\n",
    "                            \n",
    "            if coarsen_factor is not None:\n",
    "                anomalies = anomalies.coarsen(lat=coarsen_factor, lon=coarsen_factor, boundary='trim').mean()\n",
    "            \n",
    "            if flag:\n",
    "                if time_scale=='year':\n",
    "                    ensemble['time'] = np.unique(anomalies['time'])\n",
    "                elif time_scale == 'month':\n",
    "                     ensemble['time'] = anomalies['time']\n",
    "                ensemble['lat'] = anomalies['lat'].values\n",
    "                ensemble['lon'] = anomalies['lon'].values  \n",
    "                flag = False\n",
    "\n",
    "            if data is None:\n",
    "                data = [anomalies[var].values]\n",
    "            else :\n",
    "                data.append(anomalies[var].values)\n",
    "\n",
    "            ds.close()\n",
    "        ensemble[model][var] = np.array(data)\n",
    "        print()\n",
    "    return ensemble\n",
    "\n",
    "def save_data(data, model='CanESM5', var='tas', data_path='../data/', name_adder='', pkl=False):\n",
    "    n_members = data[model][var].shape[0]\n",
    "    # Create a NetCDF file\n",
    "    if not pkl :\n",
    "        with nc.Dataset(data_path + '{}_{}'.format(model, var) + name_adder + '.nc', 'w') as f:\n",
    "            # Define dimensions\n",
    "            f.createDimension('n_members', n_members)\n",
    "            f.createDimension('time', len(data['time']))\n",
    "            f.createDimension('lat', len(data['lat']))\n",
    "            f.createDimension('lon', len(data['lon']))\n",
    "\n",
    "            # Create variables\n",
    "            members_var = f.createVariable('n_members', 'i4', ('n_members',))\n",
    "            time_var = f.createVariable('time', 'f8', ('time',))\n",
    "            lat_var = f.createVariable('lat', 'f4', ('lat',))\n",
    "            lon_var = f.createVariable('lon', 'f4', ('lon',))\n",
    "            tas_var = f.createVariable(var, 'f4', ('n_members', 'time', 'lat', 'lon'))\n",
    "\n",
    "            # Assign data to variables\n",
    "            members_var[:] = np.arange(n_members)\n",
    "            time_var[:] = datetime_array = range(1716)#nc.date2num(np.array([dt.datetime(d['time.year'].values, d['time.month'].values, d['time.day'].values) for d in data['time']]), units='days since 1850-01-01 00:00:00', calendar='noleap')\n",
    "            lat_var[:] = data['lat']\n",
    "            lon_var[:] = data['lon']\n",
    "            tas_var[:] = data[model][var]\n",
    "\n",
    "            # Add attributes if necessary\n",
    "            members_var.units = 'member index'\n",
    "            time_var.units = 'time units'\n",
    "            lat_var.units = 'latitude units'\n",
    "            lon_var.units = 'longitude units'\n",
    "            tas_var.units = '{} units'.format(var)\n",
    "    else :\n",
    "        hf = h5py.File(data_path + '{}_tas'.format(model) + name_adder + '.h5', 'w')\n",
    "        hf.create_dataset('data', data=data[model][var])\n",
    "        hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11c56d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Model CanESM5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../AnchorMultivariateAnalysis/data/ForceSMIP/Training/Amon/tas/ForceSMIP/CanESM5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanESM5\u001b[39m\u001b[38;5;124m'\u001b[39m] :\n\u001b[0;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#save_data(data, model=model, var='psl')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(models, var, time_scale, ref_period, path, coarsen_factor, cp_anomalies)\u001b[0m\n\u001b[1;32m      7\u001b[0m directory \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define the file path\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m listdir \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ensemble[model] \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../AnchorMultivariateAnalysis/data/ForceSMIP/Training/Amon/tas/ForceSMIP/CanESM5'"
     ]
    }
   ],
   "source": [
    "for model in ['CanESM5'] :\n",
    "    data = load_data([model], var='tas')\n",
    "    #save_data(data, model=model, var='psl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45a24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forcesmip",
   "language": "python",
   "name": "forcesmip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
