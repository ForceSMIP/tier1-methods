{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd25e7bc-8ed7-4cdd-8783-9e28c5a76c4c",
   "metadata": {},
   "source": [
    "# Multi-model mean scaling\n",
    "\n",
    "This notebook takes the multimodel mean forced climate change (from the training dataset) and scales it to match a simulation / dataset of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d410a5-bae9-4635-b05c-63b2ac27dfab",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f10429-4098-4f4e-9ac5-9c6e380661f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xcdat as xc\n",
    "from fx import get_decimal_year_time\n",
    "import numpy as np\n",
    "import glob\n",
    "import xarray as xr\n",
    "import os\n",
    "from scipy.signal import savgol_filter\n",
    "# suppress warnings (but allow errors)\n",
    "import logging\n",
    "logging.getLogger('xcdat').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5122266-022e-4506-8699-c50f45b6a2e7",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da4c475-bd4d-4df5-aa86-cf5bbf70ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_monthly_fourth_order_polynomial(ds, lvar, monthly=True):\n",
    "    \"\"\"\n",
    "    fit_monthly_fourth_order_polynomial(ds, lvar)\n",
    "\n",
    "    Function fits a fourth order polynomial to the \"raw\" dataarray (at each \n",
    "    point) that includes both internal variability and the forced response \n",
    "    such that:\n",
    "\n",
    "        y = a*t^4 + b*t^3 + c*t^2 + d*t + e\n",
    "\n",
    "    where y is the \"raw\" time series (at each point), t is time (in units of\n",
    "    decimal year), a-e are the coefficients of the fit. The resulting fit is\n",
    "    an estimate of the forced climate response.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds (xr.Dataset)  : Dataset containing the raw (forced+internal) data\n",
    "    lvar (str)       : variable id corresponding to the dataarrays to be scaled\n",
    "    monthly (bool)   : Boolean to fit data monthly (True) or all together (False), \n",
    "                       default True\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    xr.Dataset : Dataset containing an estimate of the forced response\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    The fit is performe\n",
    "    \"\"\"\n",
    "    # ensure bounds are present\n",
    "    ds = ds.bounds.add_missing_bounds(['T'])\n",
    "    # get departures\n",
    "    ds = ds.temporal.departures(lvar, freq='month')\n",
    "    # get decimal year for polynomial fit\n",
    "    dtime = get_decimal_year_time(ds.time)\n",
    "    # get dataarray shape\n",
    "    shp = ds[lvar].shape\n",
    "    # get monthly dataarray shape\n",
    "    shp_annual = ds[lvar][::12].shape\n",
    "    # reshape dataarray for fitting [time, space]\n",
    "    Y = np.reshape(ds[lvar].values, (shp[0], -1))\n",
    "    # create output dataset\n",
    "    dsf = ds.copy()\n",
    "    # loop over and fit each month separately\n",
    "    if monthly:\n",
    "        for mm in range(12):\n",
    "            # get coeffficients\n",
    "            fit = np.polyfit(dtime[mm::12], Y[mm::12, :], 4)\n",
    "            # get time matrix to apply fit coefficients\n",
    "            x = np.expand_dims(dtime[mm::12], 1)\n",
    "            # get coefficients\n",
    "            C = np.expand_dims(fit, 0)\n",
    "            # multiply time by coefficients\n",
    "            YF = C[:, 4, :] + x*C[:, 3, :] + x**2*C[:, 2, :] + x**3*C[:, 1, :] + x**4*C[:, 0, :]\n",
    "            # reshape to correct spatial structure\n",
    "            YF = np.reshape(YF, shp_annual)\n",
    "            # add monthly fit to dataset\n",
    "            dsf[lvar].values[mm::12] = YF\n",
    "    else:\n",
    "        # get coeffficients\n",
    "        fit = np.polyfit(dtime, Y, 4)\n",
    "        # get time matrix to apply fit coefficients\n",
    "        x = np.expand_dims(dtime, 1)\n",
    "        # get coefficients\n",
    "        C = np.expand_dims(fit, 0)\n",
    "        # multiply time by coefficients\n",
    "        YF = C[:, 4, :] + x*C[:, 3, :] + x**2*C[:, 2, :] + x**3*C[:, 1, :] + x**4*C[:, 0, :]\n",
    "        # reshape to correct spatial structure\n",
    "        YF = np.reshape(YF, shp)\n",
    "        # add monthly fit to dataset\n",
    "        dsf[lvar].values = YF\n",
    "    return dsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32c7a5-66c4-47d5-a6d1-a7108fb67c29",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee6901c-9578-4d3a-81e6-c3106856b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "forcesmip_root = '/glade/campaign/cgd/cas/asphilli/ForceSMIP/'\n",
    "dpath_em = '/glade/work/pochedls/forcesmip/ensemble_mean/'\n",
    "dpath_out = '/glade/work/pochedls/forcesmip/'\n",
    "fmethod = 'fourthOrderPolynomialFit'\n",
    "vmap = {'pr': ['Amon', 'pr'],\n",
    "        'psl': ['Amon', 'psl'],\n",
    "        'tas': ['Amon', 'tas'],\n",
    "        'zmta': ['Amon', 'ta'],\n",
    "        'monmaxpr': ['Aday', 'pr'],\n",
    "        'monmaxtasmax': ['Aday', 'tasmax'],\n",
    "        'monmintasmin': ['Aday', 'tasmin'],\n",
    "        'siconc': ['OImon', 'siconc'],\n",
    "        'tos': ['Omon', 'tos']}\n",
    "models = ['CanESM5', 'CESM2', 'MIROC6', 'MIROC-ES2L', 'MPI-ESM1-2-LR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375527db-4d46-47cb-8bba-a36739eb8ac3",
   "metadata": {},
   "source": [
    "### Estimate Forced Response in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0bd2aa-b76e-411b-96ce-b0d3198aa3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "psl\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "tas\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "zmta\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "monmaxpr\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "monmaxtasmax\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "monmintasmin\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "siconc\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n",
      "tos\n",
      "   CanESM5\n",
      "   CESM2\n",
      "   MIROC6\n",
      "   MIROC-ES2L\n",
      "   MPI-ESM1-2-LR\n"
     ]
    }
   ],
   "source": [
    "# print progress\n",
    "for vid in vmap.keys():\n",
    "    # print progress\n",
    "    print(vid)\n",
    "    # get CMIP table\n",
    "    cmipTable = vmap[vid][0]\n",
    "    # get appropriate netcdf variable id\n",
    "    lvar = vmap[vid][1]\n",
    "    # loop over all training models\n",
    "    for model in models:\n",
    "        # print progress\n",
    "        print('   ' + model)\n",
    "        # specify data path\n",
    "        dpath = forcesmip_root + '/Training/' + cmipTable + '/' + vid + '/' + model\n",
    "        # get all files for model\n",
    "        mfiles = glob.glob(dpath + '/*nc')\n",
    "        # loop over all files / members\n",
    "        for fn in mfiles:\n",
    "            # get member\n",
    "            if model == 'CESM2':\n",
    "                member = '.'.join(fn.split('_')[-1].split('.')[0:2])\n",
    "            else:\n",
    "                member = fn.split('.')[0].split('_')[-1]\n",
    "            # specify output path\n",
    "            fnOut = dpath_out + '/training_predictions/' + vid + '_mon_' + model + '_' + fmethod + '_historical_ssp370_' + member + '.' + mfiles[0].split('.')[-1]\n",
    "            fnOutMonthly = dpath_out + '/training_predictions/' + vid + '_mon_' + model + '_' + fmethod + 'Monthly_historical_ssp370_' + member + '.' + mfiles[0].split('.')[-1]\n",
    "            # continue if already done\n",
    "            if os.path.exists(fnOut):\n",
    "                continue\n",
    "            # open dataset\n",
    "            ds = xc.open_dataset(fn)\n",
    "            # do fit\n",
    "            dsm = fit_monthly_fourth_order_polynomial(ds, lvar)\n",
    "            dsa = fit_monthly_fourth_order_polynomial(ds, lvar, monthly=False)\n",
    "            # save output\n",
    "            dsm.to_netcdf(fnOutMonthly)\n",
    "            dsa.to_netcdf(fnOut)\n",
    "            # close file\n",
    "            ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9020ae0-08f7-4858-bb6c-10630aef35f6",
   "metadata": {},
   "source": [
    "### Estimate Forced Response in Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dec39d-4df4-488b-83fd-670369ba62e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr\n",
      "   1E\n",
      "   1B\n",
      "   1H\n",
      "   1J\n",
      "   1I\n",
      "   1D\n",
      "   1F\n",
      "   1G\n",
      "   1A\n",
      "   1C\n",
      "psl\n",
      "   1G\n",
      "   1C\n",
      "   1I\n",
      "   1E\n",
      "   1F\n",
      "   1A\n",
      "   1J\n",
      "   1D\n",
      "   1H\n",
      "   1B\n",
      "tas\n",
      "   1F\n",
      "   1I\n",
      "   1E\n",
      "   1G\n",
      "   1D\n",
      "   1B\n",
      "   1A\n",
      "   1C\n",
      "   1H\n",
      "   1J\n",
      "zmta\n",
      "   1B\n",
      "   1I\n",
      "   1D\n",
      "   1H\n",
      "   1C\n",
      "   1J\n",
      "   1F\n",
      "   1G\n",
      "   1E\n",
      "   1A\n",
      "monmaxpr\n",
      "   1C\n",
      "   1I\n",
      "   1B\n",
      "   1F\n",
      "   1A\n",
      "   1G\n",
      "   1E\n",
      "   1J\n",
      "   1H\n",
      "   1D\n",
      "monmaxtasmax\n",
      "   1H\n",
      "   1J\n",
      "   1F\n",
      "   1E\n",
      "   1B\n",
      "   1D\n",
      "   1C\n",
      "   1I\n",
      "   1A\n",
      "   1G\n",
      "monmintasmin\n",
      "   1I\n",
      "   1E\n",
      "   1H\n",
      "   1J\n",
      "   1B\n",
      "   1D\n",
      "   1F\n",
      "   1A\n",
      "   1G\n",
      "   1C\n",
      "siconc\n",
      "tos\n",
      "   1C\n",
      "   1I\n",
      "   1E\n",
      "   1J\n",
      "   1D\n",
      "   1G\n",
      "   1F\n",
      "   1H\n",
      "   1A\n",
      "   1B\n"
     ]
    }
   ],
   "source": [
    "# first ensure output path exists\n",
    "if not os.path.exists(dpath_out + '/evaluation_predictions/'):\n",
    "    os.makedirs(dpath_out + '/evaluation_predictions/')\n",
    "\n",
    "# loop over variables\n",
    "for vid in vmap.keys():\n",
    "    # print progress\n",
    "    print(vid)\n",
    "    # get CMIP table\n",
    "    cmipTable = vmap[vid][0]\n",
    "    # get appropriate netcdf variable id\n",
    "    lvar = vmap[vid][1]\n",
    "    # get evaluation files\n",
    "    dpath = forcesmip_root + '/Evaluation-Tier1/' + cmipTable + '/' + vid\n",
    "    mfiles = glob.glob(dpath + '/*nc')\n",
    "    # loop over all evaluation models\n",
    "    for fn in mfiles:\n",
    "        # specify output path\n",
    "        member = fn.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "        print('   ' + member)\n",
    "        fnOut = dpath_out + '/evaluation_predictions/' + vid + '_' + member + '_tier1_' + fmethod + '_benchmark.nc'\n",
    "        fnOutMonthly = dpath_out + '/evaluation_predictions/' + vid + '_' + member + '_tier1_' + fmethod + 'Monthly_benchmark.nc'\n",
    "        # continue if already done\n",
    "        if os.path.exists(fnOut):\n",
    "            continue\n",
    "        # open dataset\n",
    "        ds = xc.open_dataset(fn)\n",
    "        # do fit\n",
    "        dsfm = fit_monthly_fourth_order_polynomial(ds, lvar)\n",
    "        dsfa = fit_monthly_fourth_order_polynomial(ds, lvar, monthly=False)\n",
    "        # save output\n",
    "        dsfm.to_netcdf(fnOutMonthly)\n",
    "        dsfa.to_netcdf(fnOut)\n",
    "        # close file\n",
    "        ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcdat",
   "language": "python",
   "name": "xcdat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
