{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08db5388-7169-46e0-9e4e-9ed7f7a6749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Feb 17, 2024 Created\n",
    "# Team: YNKuoJLien\n",
    "# Code creator: Yan-Ning Kuo (yk545@cornell.edu)\n",
    "#\n",
    "# ForceSMIP_function_ColorLIMnMCA_YNKuoJLien.ipynb is a script including \n",
    "# the functions necessary for conducting the forced response estimate from \n",
    "# group YNKuoJLien with ColorLIMnMCA - a combination of a Colored Noise \n",
    "# Linear Inverse Model with Colored Noise (ColorLIM; Lien, under review) \n",
    "# and Maximum Covariance Analysis (MCA).\n",
    "#\n",
    "# ColorLIM is a variant of LIM designed for a system driven by colored noise,\n",
    "# and is developed by Justin Lien (lien.justin.t8@dc.tohoku.ac.jp) with a \n",
    "# under review paper (2024) for its mathematical foundation:\n",
    "# https://arxiv.org/abs/2402.15184v1\n",
    "#\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "## Import some necessary libraries\n",
    "from os import walk\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xcat as xc\n",
    "import time as clocktime\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def mat2vec(Xmat):\n",
    "    dimsize = Xmat.shape\n",
    "    Xvec = np.empty((dimsize[0]*dimsize[1],1)) * np.nan\n",
    "    Xvec[:,0] = Xmat.reshape(dimsize[0]*dimsize[1])\n",
    "    return Xvec\n",
    "\n",
    "def Symmetrization(X):\n",
    "    Xsym = 0.5 * (X + X.T)\n",
    "    return Xsym\n",
    "\n",
    "def AntiSymmetrization(X):\n",
    "    Xantisym = 0.5 * (X - X.T)\n",
    "    return Xantisym\n",
    "\n",
    "def vec2mat(Xvec, dimsize0, dimsize1):\n",
    "    Xmat = Xvec.reshape(dimsize0, dimsize1)\n",
    "    return Xmat\n",
    "\n",
    "def com_mat(m, n):\n",
    "    if (m!=n):\n",
    "        A = np.arange(m*n)\n",
    "        A = A.reshape(m,n,order='F').copy()\n",
    "        v = A.T\n",
    "        v = v.reshape(m*n,order='F').copy()\n",
    "        P = np.eye(m*n)\n",
    "        P = P[v,:]\n",
    "    else:\n",
    "        A = np.arange(m*n)\n",
    "        A = A.reshape(m,n)\n",
    "        v = A.T\n",
    "        v = v.reshape(m*n)\n",
    "        P = np.eye(m*n)\n",
    "        P = P[v,:]\n",
    "    return P\n",
    "\n",
    "def xcorr(x, y, maxlags=5,mode='unbiased'):\n",
    "    # e.g. lags, c = xcorr(x,y,maxlags=len(x)-1)\n",
    "    c = np.correlate(x, y, mode='full')\n",
    "    idx0 = int((len(c)-1)/2);\n",
    "    idx = np.arange(idx0-2*idx0,idx0+1,1)\n",
    "    strloc = int(np.where(idx==-maxlags)[0])\n",
    "    endloc = int(np.where(idx==maxlags)[0])+1\n",
    "    if (mode=='unbiased'):\n",
    "        scale = (len(x)-np.abs(idx[strloc:endloc]))\n",
    "        ## normed np.sqrt(np.dot(x, x) * np.dot(y, y)) # this is the transformation function\n",
    "        c = np.true_divide(c[strloc:endloc],scale)\n",
    "        lags = idx[strloc:endloc]\n",
    "    return c, lags\n",
    "\n",
    "def findingLeastDampedMode(A,xvec):\n",
    "    D, U = np.linalg.eig(A)\n",
    "    V = np.linalg.inv(U).T\n",
    "    print(np.real(D))\n",
    "    ind = np.where(np.abs(np.real(D))==np.min(np.abs(np.real(D))))[0] ## np.abs(np.real(D)) smallest\n",
    "    DD = D[ind[0]] ## sort eigenvalue in desending way so that the first one will have the lowest decaying rate\n",
    "    VV = V[:,ind[0]] ## the time series of the least damped mode\n",
    "    UU = U[:,ind[0]]\n",
    "    alpha = np.dot(VV.T, xvec)\n",
    "    Xtr = np.real(np.outer(UU, alpha))\n",
    "    return Xtr\n",
    "\n",
    "def ForceSMIP_ColorLIM_trend(T, xvec, Gam):\n",
    "## Input variables: T, xvec, Gam \n",
    "#### T[ntime]: vector of time \n",
    "#### xvec[n, ntime]: vector of n*ntime;\n",
    "#### Gam[1]: noise's dependence on time\n",
    "    n = xvec.shape\n",
    "    dt = T[1] - T[0]\n",
    "    C_Num = np.dot(xvec,xvec.T) / n[1] ## Numerical solution of covariance matrix\n",
    "    ### numerical derivatives of correlation function\n",
    "    t_corr = 1 ## compute the correlation function over the domain [-t_corr, t_corr]\n",
    "    Numerical_dc_at_0 = np.empty((n[0],n[0])) * np.nan\n",
    "    Numerical_ddc_at_0 = np.empty((n[0],n[0])) * np.nan\n",
    "    Numerical_dddc_at_0 = np.empty((n[0],n[0])) * np.nan\n",
    "    for j in range(n[0]):\n",
    "        for k in range(n[0]):\n",
    "            [c,lags] = xcorr(xvec[j,:],xvec[k,:],maxlags=round(t_corr/dt),mode='unbiased');\n",
    "            idx = int((len(lags)-1)/2)\n",
    "            Numerical_dc_at_0[j,k] = np.dot([-3/2, 2, -1/2], c[idx:(idx+2)+1])/dt; # Forward - Second order\n",
    "            Numerical_ddc_at_0[j,k] = np.dot([2, -5, 4, -1],c[idx:(idx+3)+1])/dt**2; # Forward - Second order\n",
    "            Numerical_dddc_at_0[j,k] = np.dot([1/8, -1, 13/8, 0, -13/8, 1, -1/8],\\\n",
    "                                              c[(idx-3):(idx+3)+1])/dt**3; # Central - Fourth order\n",
    "    N0 = C_Num;\n",
    "    N1 = Numerical_dc_at_0;\n",
    "    N2 = Numerical_ddc_at_0;\n",
    "    N3 = Numerical_dddc_at_0;\n",
    "    \n",
    "    X = 0.5 * (N1+N0/Gam);\n",
    "    Z = Symmetrization(-N2);\n",
    "    Y = Symmetrization(0.5 * (N2 - N0/Gam**2))\n",
    "    W = AntiSymmetrization(1/Gam**2 * N1 - N3)\n",
    "\n",
    "    A_vec_1 = np.concatenate((np.kron(X.T,np.eye(n[0]))+np.kron(np.eye(n[0]),X.T)@com_mat(n[0],n[0]),\\\n",
    "             np.kron(Y.T,np.eye(n[0]))-np.kron(np.eye(n[0]),Y)@com_mat(n[0],n[0])),axis = 0)\n",
    "    A_vec_2 = np.concatenate((-mat2vec(Z),-mat2vec(W)),axis = 0)\n",
    "    A_Num = vec2mat(np.linalg.lstsq(A_vec_1,A_vec_2)[0], \\\n",
    "                    int(n[0]), int(n[0]))\n",
    "\n",
    "    X_least_damped = findingLeastDampedMode(A_Num,xvec)\n",
    "    \n",
    "    return X_least_damped\n",
    "\n",
    "def ForceSMIP_MCA(A, B):\n",
    "    # MCA analysis of the climate field, note that the climate field has to be in 2D format [time, space]\n",
    "    # output: a dictionary, containing MCA_A [mode, space] and MCA_B in [space, mode], PC in [time, mode], lamb is the portion of explained variance by each PC\n",
    "    \n",
    "    normA = np.sqrt(np.mean(np.mean(A**2, axis=0)))\n",
    "    A = A/normA\n",
    "    normB = np.sqrt(np.mean(np.mean(B**2, axis=0)))\n",
    "    B = B/normB\n",
    "    U, S, Vh = np.linalg.svd(np.dot(B.T,A), full_matrices=False)\n",
    "\n",
    "    s = dict()\n",
    "    s[\"MCA_Pattern_A\"] = Vh\n",
    "    s[\"MCA_Pattern_B\"] = U.T\n",
    "    s[\"MCA_A\"] = np.dot(A, Vh.T)\n",
    "    s[\"MCA_B\"] = np.dot(B, U)\n",
    "    D = S ** 2\n",
    "    s[\"D\"] = D / np.sum(D)\n",
    "    s[\"normA\"] = normA\n",
    "    s[\"normB\"] = normB\n",
    "    return s\n",
    "\n",
    "def ForceSMIP_EOF(A):\n",
    "    # Adapted form Tongtong Xu's function [adding the standardization for PCs/EOFs with the square root of eigen values]\n",
    "    # EOF analysis of the climate field, note that the climate field has to be in 2D format [time, space]\n",
    "    # output: a dictionary, containing EOF in [mode, space], PC in [time, mode], lamb is the portion of explained variance by each PC\n",
    "    \n",
    "    norm = np.sqrt(np.mean(np.mean(A**2, axis=0)))\n",
    "    A = A/norm\n",
    "    \n",
    "    U, S, V = np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "    s = dict()\n",
    "    s[\"EOF\"] = np.dot(np.diag(1/S),V)\n",
    "    s[\"PC\"] = np.dot(A, s[\"EOF\"].T)\n",
    "    s[\"S\"] = S\n",
    "    s[\"norm\"] = norm\n",
    "    return s\n",
    "\n",
    "def ForceSMIP_read_zmta(fname,varname):\n",
    "    # this function reads in the data from netcdf\n",
    "    # input: fname is a string containing (the path and) the name of the ncfile\n",
    "    #        varname is a string containing the name of the climate variable to be read, e.g., \"\"\n",
    "    # output: a dictionary, containing the 3D climate field, lon & lat in 2D, and time\n",
    "    \n",
    "    data = xr.open_dataset(fname)\n",
    "    \n",
    "    s = dict()\n",
    "    s[\"lat\"],s[\"plev\"] = np.meshgrid(data[\"lat\"],data[\"plev\"])\n",
    "    s[varname] = data[varname].values\n",
    "    s[\"mask\"] = 1 - 0*s[varname].sum(axis=0)\n",
    "    s[\"time\"] = data[\"time\"]\n",
    "    s[\"plev_axis\"] = data[\"plev\"]\n",
    "    s[\"lat_axis\"] = data[\"lat\"]\n",
    "    data.close()\n",
    "    return s\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# These functions are copied from ForceSMIP_LIM (generated by Tongtong Xu)\n",
    "# -------------------------------------------------------------------------\n",
    "def ForceSMIP_read(fname,varname):\n",
    "    # this function reads in the data from netcdf\n",
    "    # input: fname is a string containing (the path and) the name of the ncfile\n",
    "    #        varname is a string containing the name of the climate variable to be read, e.g., \"\"\n",
    "    # output: a dictionary, containing the 3D climate field, lon & lat in 2D, and time\n",
    "    \n",
    "    data = xr.open_dataset(fname)\n",
    "    \n",
    "    s = dict()\n",
    "    s[\"lon\"],s[\"lat\"] = np.meshgrid(data[\"lon\"],data[\"lat\"])\n",
    "    s[varname] = data[varname].values\n",
    "    s[\"mask\"] = 1 - 0*s[varname].sum(axis=0)\n",
    "    s[\"time\"] = data[\"time\"]\n",
    "    s[\"lon_axis\"] = data[\"lon\"]\n",
    "    s[\"lat_axis\"] = data[\"lat\"]\n",
    "    data.close()\n",
    "    return s\n",
    "\n",
    "def ForceSMIP_XYT_into_ZT(z,mask):\n",
    "    # convert 3D array into 2D, such that the climate field is represented in [time, space]\n",
    "    # input: z is the 3D array of [time, lat, lon], mask is the 2D array of [lat,lon], containing either 1 or nan\n",
    "    \n",
    "    T, J, I = z.shape\n",
    "    z = np.multiply(z,np.tile(mask[np.newaxis,:,:], (T, 1, 1)))\n",
    "    z = z.reshape(T,J*I)\n",
    "    idx = np.where(~np.isnan(z[0, :]))[0]\n",
    "    zout = z[:,idx]\n",
    "    return zout\n",
    "\n",
    "def ForceSMIP_ZT_into_XYT(z,mask):\n",
    "    # convert 2D array back to 3D, such that the climate field is represented in [time, lat, lon]\n",
    "    # input: z is the 2D array of [time, space], mask is the 2D array of [lat,lon], containing either 1 or nan\n",
    "    if len(z.shape)==1:\n",
    "        J, I = mask.shape\n",
    "        idx = np.where(~np.isnan(mask.reshape(J*I)))[0]\n",
    "        zout = np.zeros((1,J*I))\n",
    "        zout[0,idx] = z\n",
    "        zout = np.multiply(zout[0,:].reshape(J,I),mask)\n",
    "    else:\n",
    "        J, I = mask.shape\n",
    "        T, _ = z.shape\n",
    "        idx = np.where(~np.isnan(mask.reshape(J*I)))[0]\n",
    "        zout = np.zeros((T,J*I))\n",
    "        zout[:,idx] = z\n",
    "        zout = np.multiply(zout.reshape(T,J,I),np.tile(mask[np.newaxis,:,:], (T, 1, 1)))\n",
    "    return zout\n",
    "\n",
    "def ForceSMIP_removeSeas(z,time):\n",
    "    # this function removes the seasonal mean climatology\n",
    "    # input: z is the 3D climate field [time, lat, lon], time is the time series (xarray format)\n",
    "    # output: seasonal mean fields (seas in [season, lat, lon]), and anomalies in the same size as z\n",
    "    \n",
    "    monlist = time.dt.month.values\n",
    "    T, J, I = z.shape\n",
    "\n",
    "    # get seasonality matrices\n",
    "    seas = np.zeros((12, J, I))\n",
    "    for i in range(1, 13):\n",
    "        loc = monlist == i\n",
    "        seas[i-1, :, :] = np.mean(z[loc, :, :], axis=0)\n",
    "\n",
    "    # get anomaly after removing seasonality\n",
    "    ano = np.zeros_like(z)\n",
    "    for i in range(1, 13):\n",
    "        loc = monlist == i\n",
    "        ano[loc, :, :] = z[loc, :, :] - seas[i-1, :, :]\n",
    "    return seas,ano\n",
    "    \n",
    "def ForceSMIP_lim_trend(X,tau0):\n",
    "    # derive the LIM based trend\n",
    "    # input: X is 2D field in [mode, time], tau0 is the training lag\n",
    "    # output: u, the spatial pattern of the least damped mode; alpha, the time series associated with the least damped mode;\n",
    "    #         X_least_damped is in [mode, time], the trend representation in PC space\n",
    "\n",
    "    X0 = X[:,:-tau0]\n",
    "    Xtau = X[:,tau0:]\n",
    "\n",
    "    C0 = np.dot(X0, X0.T) / (X0.shape[1] - 1)\n",
    "    Ctau = np.dot(Xtau, X0.T) / (X0.shape[1] - 1)\n",
    "\n",
    "    # linear operator\n",
    "    G = np.dot(Ctau,np.linalg.pinv(C0))\n",
    "    D,U = np.linalg.eig(G)\n",
    "    D = np.log(D)/tau0\n",
    "    V = np.linalg.inv(U).T\n",
    "\n",
    "    # sort modes\n",
    "    loc = np.argsort(-np.real(D))\n",
    "    sigma = -1 / np.real(D[loc])\n",
    "    UU = U[:, loc]\n",
    "    VV = V[:, loc]\n",
    "\n",
    "    # identify the least damped mode\n",
    "    u = UU[:, 0]\n",
    "    v = VV[:, 0]\n",
    "    alpha = np.dot(v, X)\n",
    "\n",
    "    X_least_damped = np.real(np.outer(u, alpha))\n",
    "    return X_least_damped\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# These functions are copied from ForceSMIP_LFCA (generated by Robert Wills)\n",
    "# -------------------------------------------------------------------------\n",
    "from scipy.signal import convolve, butter, filtfilt\n",
    "### Helper functions ###\n",
    "def low_pass_weights(window, cutoff):\n",
    "    \"\"\"Calculate weights for a low pass Lanczos filter.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    window: int\n",
    "        The length of the filter window.\n",
    "\n",
    "    cutoff: float\n",
    "        The cutoff frequency in inverse time steps.\n",
    "        \n",
    "    References\n",
    "    ----------\n",
    "        from https://scitools.org.uk/iris/docs/v1.2/examples/graphics/SOI_filtering.html\n",
    "\n",
    "    \"\"\"\n",
    "    order = ((window - 1) // 2 ) + 1\n",
    "    nwts = 2 * order + 1\n",
    "    w = np.zeros([nwts])\n",
    "    n = nwts // 2\n",
    "    w[n] = 2 * cutoff\n",
    "    k = np.arange(1., n)\n",
    "    sigma = np.sin(np.pi * k / n) * n / (np.pi * k)\n",
    "    firstfactor = np.sin(2. * np.pi * cutoff * k) / (np.pi * k)\n",
    "    w[n-1:0:-1] = firstfactor * sigma\n",
    "    w[n+1:-1] = firstfactor * sigma\n",
    "    return w[1:-1]\n",
    "\n",
    "def filter_padding(ts, window, ftype='mirror', detrend=True, detrend_poly=1): \n",
    "    ts_pad = np.zeros(2*window+len(ts))\n",
    "    if detrend:\n",
    "        t = np.arange(len(ts))\n",
    "        z = np.polyfit(t,ts,detrend_poly)\n",
    "        p = np.poly1d(z)\n",
    "        ts_in = ts-p(t)\n",
    "    else:\n",
    "        ts_in = ts\n",
    "    ts_pad[window:-window] = ts_in[:]\n",
    "    if ftype == 'mirror':\n",
    "        ts_pad[:window] = ts_in[:window][::-1]\n",
    "        ts_pad[-window:] = ts_in[-window:][::-1]\n",
    "    elif ftype == 'periodic':\n",
    "        ts_pad[:window] = ts_in[-window:]\n",
    "        ts_pad[-window:] = ts_in[:window]\n",
    "    else:\n",
    "        raise ValueError('in filter_padding: ftype must be one of \"mirror\" or \"periodic\".')\n",
    "    if detrend:\n",
    "        t_pad = np.arange(-window,len(ts)+window)\n",
    "        ts_pad = ts_pad+p(t_pad)\n",
    "    return ts_pad\n",
    "\n",
    "def filter_ts(ts, cutoff, filter_type='lanczos', padding_type='mirror', detrend=True, detrend_poly=1): \n",
    "    lanczos_weights=low_pass_weights(cutoff*2+1,1./cutoff) # weights for Lanczos filter\n",
    "    n_pad=int(np.ceil(len(lanczos_weights)/2))\n",
    "    \n",
    "    # Padding\n",
    "    ts_mirr=filter_padding(ts,n_pad,padding_type,detrend=detrend,detrend_poly=detrend_poly)\n",
    "    \n",
    "    # Filtering\n",
    "    if filter_type=='lanczos':\n",
    "        # Lanczos filter\n",
    "        return convolve(ts_mirr,lanczos_weights,'same')[n_pad:-n_pad]\n",
    "    elif filter_type=='butter':\n",
    "        # Butterworth filter\n",
    "        # TODO: here, the cutoff frequency needs to be doubled\n",
    "        # to obtain the same result as for Lanczos - why?\n",
    "        b,a = butter(3,1./(cutoff/2),btype='low')\n",
    "        return filtfilt(b,a,ts_mirr)[n_pad:-n_pad]\n",
    "    else:\n",
    "        raise ValueError('in filter_ts: filter_type must be one of \"lanczos\" or \"butter\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932f928b-b1ad-4db1-9040-87186e280804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lintrd(input_x,input_y):\n",
    "        shapey = len(input_y.shape)\n",
    "        if (shapey==1):\n",
    "                trd = np.empty((1,)) * np.nan\n",
    "                trd = np.polyfit(input_x,input_y,1)[0]\n",
    "                pred = np.polyval(np.polyfit(input_x,input_y,1),input_x)\n",
    "                residual = np.empty((len(input_x),))\n",
    "                residual = input_y[:]-pred[:]\n",
    "                var_residual = (1/(len(input_x)-1)*np.nansum(residual*residual))\n",
    "                var_x = (1/(len(input_x)-1)*np.nansum((input_x-np.nanmean(input_x))*(input_x-np.nanmean(input_x))))\n",
    "                trd_std = np.sqrt((var_residual/((len(input_x)-1)*var_x)))\n",
    "        elif (shapey==2):\n",
    "                trd = np.empty((input_y.shape[1],)) * np.nan\n",
    "                trd_std = np.empty((input_y.shape[1],)) * np.nan\n",
    "                for i in range(len(input_y[0])):\n",
    "                        trd[i] = np.polyfit(input_x,input_y[:,i],1)[0]\n",
    "                        pred = np.polyval(np.polyfit(input_x,input_y[:,i],1),input_x)\n",
    "                        residual = input_y[:,i]-pred\n",
    "                        var_residual = (1/(len(input_x)-1)*np.nansum(residual*residual))\n",
    "                        var_x = (1/(len(input_x)-1)*np.nansum((input_x-np.nanmean(input_x))*(input_x-np.nanmean(input_x))))\n",
    "                        trd_std[i] = np.sqrt((var_residual/((len(input_x)-1)*var_x)))\n",
    "        elif (shapey==3):\n",
    "                trd = np.empty((input_y.shape[1],input_y.shape[2])) * np.nan\n",
    "                trd_std = np.empty((input_y.shape[1],input_y.shape[2])) * np.nan\n",
    "                for i in range(len(trd)):\n",
    "                        for j in range(len(trd[0])):\n",
    "                                if (np.isnan(input_y[0,i,j])==False):\n",
    "                                    trd[i,j] = np.polyfit(input_x,input_y[:,i,j],1)[0]\n",
    "                                    pred = np.polyval(np.polyfit(input_x,input_y[:,i,j],1),input_x)\n",
    "                                    residual = input_y[:,i,j]-pred\n",
    "                                    var_residual = (1/(len(input_x)-1)*np.nansum(residual*residual))\n",
    "                                    var_x = (1/(len(input_x)-1)*np.nansum((input_x-np.nanmean(input_x))*(input_x-np.nanmean(input_x))))\n",
    "                                    trd_std[i,j] = np.sqrt((var_residual/((len(input_x)-1)*var_x)))\n",
    "        return trd, trd_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6d4d3-6bd4-4ccb-b494-bd45e5fb7580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
